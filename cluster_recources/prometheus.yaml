apiVersion: template.openshift.io/v1
kind: Template
metadata:
  name: prometheus
  annotations:
    "openshift.io/display-name": Prometheus
    description: |
      A monitoring solution for an OpenShift cluster - collect and gather metrics and alerts from nodes, services, and the infrastructure. This is a tech preview feature.
    iconClass: fa fa-cogs
    tags: "monitoring,prometheus, alertmanager,time-series"
parameters:
- description: The namespace to instantiate prometheus under. Defaults to 'kube-system'.
  name: NAMESPACE
  # value: openshift-metrics
- description: The location of the proxy image
  name: IMAGE_PROXY
  value: openshift/oauth-proxy:v1.1.0
- description: The location of the prometheus image
  name: IMAGE_PROMETHEUS
  value: openshift/prometheus:v2.5.0
- description: The session secret for the proxy
  name: SESSION_SECRET
  generate: expression
  from: "[a-zA-Z0-9]{43}"
- description: Storage type.
  displayName: Starage type
  name: STORAGE_ACCSESS_MODE
  value: "ReadWriteOnce"
- description: Storage size.
  displayName: Jenkins Starage
  name: STORAGE_SIZE
  value: "10Gi"

objects:

#Create Project Monioring
- apiVersion: project.openshift.io/v1
  kind: Project
  metadata:
    annotations:
      openshift.io/description: ""
      openshift.io/display-name: ""
    name: ${NAMESPACE}
  spec:
    finalizers:
    - kubernetes
  status:
    phase: Active

# Authorize the prometheus service account to read data about the cluster
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: prometheus
    namespace: "${NAMESPACE}"
    annotations:
      serviceaccounts.openshift.io/oauth-redirectreference.prom: '{"kind":"OAuthRedirectReference","apiVersion":"v1","reference":{"kind":"Route","name":"prometheus"}}'

# Create a service account for accessing prometheus data
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: prometheus-reader
    namespace: "${NAMESPACE}"

# Create a service account for prometheus to use to scrape other infrastructure components
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: prometheus-scraper
    namespace: "${NAMESPACE}"

- apiVersion: v1
  kind: Secret
  metadata:
    name: prometheus-scraper
    namespace: "${NAMESPACE}"
    annotations:
      kubernetes.io/service-account.name: prometheus-scraper
  type: kubernetes.io/service-account-token

- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    name: prometheus-scraper
    labels:
      kubernetes.io/cluster-service: "true"
      addonmanager.kubernetes.io/mode: Reconcile
  rules:
    - apiGroups:
        - ""
      resources:
        - nodes
        - nodes/metrics
        - routers/metrics
        - services
        - endpoints
        - pods
      verbs:
        - get
        - list
        - watch
    - apiGroups:
        - ""
      resources:
        - configmaps
      verbs:
        - get
    - nonResourceURLs:
        - "/metrics"
      verbs:
        - get

- apiVersion: authorization.openshift.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: prometheus-scraper
  roleRef:
    name: prometheus-scraper
  subjects:
  - kind: ServiceAccount
    name: prometheus-scraper
    namespace: "${NAMESPACE}"

- apiVersion: authorization.openshift.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: prometheus-cluster-reader
  roleRef:
    name: cluster-reader
  subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: "${NAMESPACE}"

- apiVersion: authorization.openshift.io/v1
  kind: RoleBinding
  metadata:
    name: prometheus-reader
    namespace: "${NAMESPACE}"
  roleRef:
    name: view
  subjects:
  - kind: ServiceAccount
    name: prometheus-reader
    namespace: "${NAMESPACE}"

# Create a fully end-to-end TLS connection to the prometheus proxy
- apiVersion: route.openshift.io/v1
  kind: Route
  metadata:
    name: prometheus
    namespace: "${NAMESPACE}"
  spec:
    to:
      name: prometheus
    tls:
      termination: Reencrypt
      insecureEdgeTerminationPolicy: Redirect
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/scheme: https
      service.alpha.openshift.io/serving-cert-secret-name: prometheus-tls
    labels:
      name: prometheus
    name: prometheus
    namespace: "${NAMESPACE}"
  spec:
    ports:
    - name: prometheus
      port: 443
      protocol: TCP
      targetPort: 8443
    selector:
      app: prometheus

- apiVersion: v1
  kind: Secret
  metadata:
    name: prometheus-proxy
    namespace: "${NAMESPACE}"
  stringData:
    session_secret: "${SESSION_SECRET}="

#Create Persistent Volume Claim    
- apiVersion: "v1"
  kind: "PersistentVolumeClaim"
  metadata:
    name: prometheus-storage
    namespace: "${NAMESPACE}"
  spec:
    accessModes:
      - ${STORAGE_ACCSESS_MODE}
    resources:
      requests:
        storage: ${STORAGE_SIZE}

- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      app: prometheus
    name: prometheus
    namespace: "${NAMESPACE}"
  spec:
    updateStrategy:
      type: RollingUpdate
    podManagementPolicy: Parallel
    selector:
      matchLabels:
        app: prometheus
    template:
      metadata:
        labels:
          app: prometheus
        name: prometheus
      spec:
        serviceAccountName: prometheus
        containers:
        # Deploy Prometheus behind an oauth proxy
        - name: prom-proxy
          image: ${IMAGE_PROXY}
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 8443
            name: web
          args:
          - -provider=openshift
          - -https-address=:8443
          - -http-address=
          - -email-domain=*
          - -upstream=http://localhost:9090
          - -client-id=system:serviceaccount:${NAMESPACE}:prometheus
          - -openshift-ca=/etc/pki/tls/cert.pem
          - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          - '-openshift-sar={"resource": "namespaces", "verb": "get", "resourceName": "${NAMESPACE}", "namespace": "${NAMESPACE}"}'
          - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get", "resourceName": "${NAMESPACE}", "namespace": "${NAMESPACE}"}}'
          - -tls-cert=/etc/tls/private/tls.crt
          - -tls-key=/etc/tls/private/tls.key
          - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
          - -cookie-secret-file=/etc/proxy/secrets/session_secret
          - -skip-auth-regex=^/metrics
          volumeMounts:
          - mountPath: /etc/tls/private
            name: prometheus-tls-secret
          - mountPath: /etc/proxy/secrets
            name: prometheus-proxy-secret
          - mountPath: /prometheus
            name: prometheus-data

        - name: prometheus
          args:
          - --storage.tsdb.retention=6h
          - --config.file=/etc/prometheus/prometheus.yml
          - --web.listen-address=localhost:9090
          image: ${IMAGE_PROMETHEUS}
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - /bin/bash
              - -c
              - |-
                set -euo pipefail;
                touch /tmp/prometheusconfig.hash;
                if [[ $(find /etc/prometheus -type f | sort | xargs md5sum | md5sum) != $(cat /tmp/prometheusconfig.hash) ]]; then
                  find /etc/prometheus -type f | sort | xargs md5sum | md5sum > /tmp/prometheusconfig.hash;
                  kill -HUP 1;
                fi
            initialDelaySeconds: 60
            periodSeconds: 60
          volumeMounts:
          - mountPath: /etc/prometheus
            name: prometheus-config
          - mountPath: /prometheus
            name: prometheus-data
          - mountPath: /var/run/secrets/kubernetes.io/scraper
            name: prometheus-scraper-secret


        restartPolicy: Always
        volumes:

        - name: prometheus-config
          configMap:
            defaultMode: 420
            name: prometheus
        - name: prometheus-scraper-secret
          secret:
            secretName: prometheus-scraper
        - name: prometheus-proxy-secret
          secret:
            secretName: prometheus-proxy
        - name: prometheus-tls-secret
          secret:
            secretName: prometheus-tls
        - name: prometheus-data
          persistentVolumeClaim:
            claimName: prometheus-storage

- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: prometheus
    namespace: "${NAMESPACE}"
  data:

    prometheus.yml: |
      scrape_configs:
      - job_name: prometheus
        static_configs:
        - targets:
          - localhost:9090

      - job_name: kubernetes-apiservers
        kubernetes_sd_configs:
        - role: endpoints
        relabel_configs:
        - action: keep
          regex: default;kubernetes;https
          source_labels:
          - __meta_kubernetes_namespace
          - __meta_kubernetes_service_name
          - __meta_kubernetes_endpoint_port_name
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

      - job_name: kubernetes-nodes-kubelet
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

      - job_name: kubernetes-nodes-cadvisor
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __metrics_path__
          replacement: /metrics/cadvisor
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

      - job_name: kubernetes-service-endpoints
          
        kubernetes_sd_configs:
        - role: endpoints
        relabel_configs:
        - action: keep
          regex: true
          source_labels:
          - __meta_kubernetes_service_annotation_prometheus_io_scrape
        - action: replace
          regex: (https?)
          source_labels:
          - __meta_kubernetes_service_annotation_prometheus_io_scheme
          target_label: __scheme__
        - action: replace
          regex: (.+)
          source_labels:
          - __meta_kubernetes_service_annotation_prometheus_io_path
          target_label: __metrics_path__
        - action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          source_labels:
          - __address__
          - __meta_kubernetes_service_annotation_prometheus_io_port
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - action: replace
          source_labels:
          - __meta_kubernetes_namespace
          target_label: kubernetes_namespace
        - action: replace
          source_labels:
          - __meta_kubernetes_service_name
          target_label: kubernetes_name
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: prometheus-node-exporter
    namespace: "${NAMESPACE}"
  # You must grant hostaccess via: oc adm policy add-scc-to-user -z prometheus-node-exporter hostaccess
  # in order for the node-exporter to access the host network and mount /proc and /sys from the host

- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/scrape: "true"
    labels:
      app: prometheus-node-exporter
    name: prometheus-node-exporter
    namespace: "${NAMESPACE}"
  spec:
    clusterIP: None
    ports:
    - name: scrape
      port: 9100
      protocol: TCP
      targetPort: 9100
    selector:
      app: prometheus-node-exporter

- apiVersion: extensions/v1beta1
  kind: DaemonSet
  metadata:
    name: prometheus-node-exporter
    namespace: "${NAMESPACE}"
    labels:
      app: prometheus-node-exporter
      role: monitoring
  spec:
    updateStrategy:
      type: RollingUpdate
    template:
      metadata:
        labels:
          app: prometheus-node-exporter
          role: monitoring
        name: prometheus-exporter
      spec:
        serviceAccountName: prometheus-node-exporter
        hostNetwork: true
        hostPID: true
        containers:
        - image: openshift/prometheus-node-exporter:v0.16.0
          args:
          - "--path.procfs=/host/proc"
          - "--path.sysfs=/host/sys"
          name: node-exporter
          ports:
          - containerPort: 9100
            name: scrape
          resources:
            requests:
              memory: 30Mi
              cpu: 100m
            limits:
              memory: 50Mi
              cpu: 200m
          volumeMounts:
          - name: proc
            readOnly:  true
            mountPath: /host/proc
          - name: sys
            readOnly: true
            mountPath: /host/sys
        volumes:
        - name: proc
          hostPath:
            path: /proc
        - name: sys
          hostPath:
            path: /sys

#kube-state-metrics

- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: kube-state-metrics
    namespace: "${NAMESPACE}"
    labels:
      k8s-app: kube-state-metrics
      kubernetes.io/cluster-service: "true"
      addonmanager.kubernetes.io/mode: Reconcile
      version: v1.3.0
  spec:
    selector:
      matchLabels:
        k8s-app: kube-state-metrics
        version: v1.3.0
    replicas: 1
    template:
      metadata:
        labels:
          k8s-app: kube-state-metrics
          version: v1.3.0
      spec:
        priorityClassName: system-cluster-critical
        serviceAccountName: kube-state-metrics
        containers:
        - name: kube-state-metrics
          image: quay.io/coreos/kube-state-metrics:v1.3.0
          ports:
          - name: http-metrics
            containerPort: 8080
          - name: telemetry
            containerPort: 8081
          readinessProbe:
            httpGet:
              path: /healthz
              port: 8080
            initialDelaySeconds: 5
            timeoutSeconds: 5
        - name: addon-resizer
          image: k8s.gcr.io/addon-resizer:1.8.6
          resources:
            limits:
              cpu: 100m
              memory: 30Mi
            requests:
              cpu: 100m
              memory: 30Mi
          env:
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
          command:
            - /pod_nanny
            - --config-dir=/etc/config
            - --container=kube-state-metrics
            - --cpu=100m
            - --extra-cpu=1m
            - --memory=100Mi
            - --extra-memory=2Mi
            - --threshold=5
            - --deployment=kube-state-metrics
        volumes:
          - name: config-volume
            configMap:
              name: kube-state-metrics-config

  # Config map for resource configuration.
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: kube-state-metrics-config
    namespace: "${NAMESPACE}"
    labels:
      k8s-app: kube-state-metrics
      kubernetes.io/cluster-service: "true"
      addonmanager.kubernetes.io/mode: Reconcile
  data:
    NannyConfiguration: |-
      apiVersion: nannyconfig/v1alpha1
      kind: NannyConfiguration

- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: kube-state-metrics
    namespace: "${NAMESPACE}"
    labels:
      kubernetes.io/cluster-service: "true"
      addonmanager.kubernetes.io/mode: Reconcile

- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRole
  metadata:
    name: kube-state-metrics
    labels:
      kubernetes.io/cluster-service: "true"
      addonmanager.kubernetes.io/mode: Reconcile
  rules:
  - apiGroups: [""]
    resources:
    - configmaps
    - secrets
    - nodes
    - pods
    - services
    - resourcequotas
    - replicationcontrollers
    - limitranges
    - persistentvolumeclaims
    - persistentvolumes
    - namespaces
    - endpoints
    verbs: ["list", "watch"]
  - apiGroups: ["extensions"]
    resources:
    - daemonsets
    - deployments
    - replicasets
    verbs: ["list", "watch"]
  - apiGroups: ["apps"]
    resources:
    - statefulsets
    verbs: ["list", "watch"]
  - apiGroups: ["batch"]
    resources:
    - cronjobs
    - jobs
    verbs: ["list", "watch"]
  - apiGroups: ["autoscaling"]
    resources:
    - horizontalpodautoscalers
    verbs: ["list", "watch"]

- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    name: kube-state-metrics-resizer
    namespace: "${NAMESPACE}"
    labels:
      kubernetes.io/cluster-service: "true"
      addonmanager.kubernetes.io/mode: Reconcile
  rules:
  - apiGroups: [""]
    resources:
    - pods
    verbs: ["get"]
  - apiGroups: ["extensions"]
    resources:
    - deployments
    resourceNames: ["kube-state-metrics"]
    verbs: ["get", "update"]

- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: kube-state-metrics
    labels:
      kubernetes.io/cluster-service: "true"
      addonmanager.kubernetes.io/mode: Reconcile
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: kube-state-metrics
  subjects:
  - kind: ServiceAccount
    name: kube-state-metrics
    namespace: "${NAMESPACE}"

- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    name: kube-state-metrics
    namespace: "${NAMESPACE}"
    labels:
      kubernetes.io/cluster-service: "true"
      addonmanager.kubernetes.io/mode: Reconcile
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: kube-state-metrics-resizer
  subjects:
  - kind: ServiceAccount
    name: kube-state-metrics
    namespace: "${NAMESPACE}"

- apiVersion: v1
  kind: Service
  metadata:
    name: kube-state-metrics
    namespace: "${NAMESPACE}"
    labels:
      kubernetes.io/cluster-service: "true"
      addonmanager.kubernetes.io/mode: Reconcile
      kubernetes.io/name: "kube-state-metrics"
    annotations:
      prometheus.io/scrape: 'true'
  spec:
    ports:
    - name: http-metrics
      port: 8080
      targetPort: http-metrics
      protocol: TCP
    - name: telemetry
      port: 8081
      targetPort: telemetry
      protocol: TCP
    selector:
      k8s-app: kube-state-metrics